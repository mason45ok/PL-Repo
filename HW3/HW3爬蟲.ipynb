{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request 原始碼\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url=\"https://www.ptt.cc/bbs/Stock/index6651.html\"\n",
    "headers={\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res = requests.get(url , headers=headers)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BeautifilSoup解析\n",
    "soup=bs(res.text,\"lxml\")\n",
    "data=soup.select(\"div.r-ent\")\n",
    "#print(data[1])\n",
    "#print(len(data))\n",
    "for ele in data:\n",
    "    #print(ele)\n",
    "    title = ele.select(\"div.title\")[0].text\n",
    "    print(\"標題 :\",title)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#解析標題/時間/推文/連結 自訂函式\n",
    "\n",
    "def get_parsing_data(soup):\n",
    "    data = soup.select(\"div.r-ent\")\n",
    "    result = []\n",
    "    \n",
    "    for sample in data:\n",
    "        #標題\n",
    "        title = sample.select(\"div.title\")[0].text.strip()\n",
    "        \n",
    "        if \"公告\" in title or \"閒聊\" in title or \"創作\" in title or \"刪除\" in title:\n",
    "            continue\n",
    "       \n",
    "        #時間\n",
    "        time = sample.select(\"div.date\")[0].text.strip()\n",
    "        \n",
    "        #推文量\n",
    "        push_num = sample.select(\"span.hl\")[0].text if len(sample.select(\"span.hl\")) > 0 else 0\n",
    "        \n",
    "        #作者\n",
    "        author = sample.select(\"div.author\")[0].text.strip()\n",
    "        \n",
    "        #連結\n",
    "        raw_link = sample.select(\"div.title a\")[0][\"href\"]\n",
    "        domain_name = \"https://www.ptt.cc\"\n",
    "        link = domain_name + raw_link\n",
    "        result.append({\n",
    "            \"title\": title,\n",
    "            \"time\": time,\n",
    "            \"author\": author,\n",
    "            \"push_num\": push_num,\n",
    "            \"link\": link\n",
    "        })\n",
    "    return result\n",
    "\n",
    "get_parsing_data(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request 原始碼\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "url=\"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "headers={\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "res = requests.get(url , headers = headers)\n",
    "soup = bs(res.text,\"lxml\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#翻頁\n",
    "previous_page = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "previous_page = domain_name + previous_page\n",
    "print(previous_page)\n",
    "\n",
    "page_num = (previous_page.replace(\"https://www.ptt.cc/bbs/Stock/index\",\"\").replace(\".html\",\"\"))\n",
    "for i in range(5):\n",
    "    print(\"https://www.ptt.cc/bbs/Stock/index{}.html\".format( int(page_num)-i ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合體程式\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "#抓取首頁資料\n",
    "url=\"https://www.ptt.cc/bbs/Stock/index.html\"\n",
    "headers={\n",
    "    \"user-agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "domain_name = \"https://www.ptt.cc\"\n",
    "\n",
    "res = requests.get(url , headers = headers)\n",
    "\n",
    "soup = bs(res.text,\"lxml\")\n",
    "\n",
    "#解析首頁資料\n",
    "output = []\n",
    "result = get_parsing_data(soup)\n",
    "output += result\n",
    "\n",
    "#抓取分頁資料\n",
    "previous_page = soup.select(\"div#action-bar-container div.btn-group-paging a\")[1][\"href\"]\n",
    "previous_page = domain_name + previous_page\n",
    "\n",
    "page_num = (previous_page.replace(\"https://www.ptt.cc/bbs/Stock/index\",\"\").replace(\".html\",\"\"))\n",
    "for i in range(5):\n",
    "    url = (\"https://www.ptt.cc/bbs/Stock/index{}.html\".format( int(page_num)-i ))\n",
    "    \n",
    "    res = requests.get(url , headers = headers)\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "    result = get_parsing_data(soup)\n",
    "    output += result\n",
    "    print(\"{} is ok\".format(url))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存入結果到.csv檔案中\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(output)\n",
    "df.to_csv(\"ptt-stock.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = df.to_json(orient='records', force_ascii=False)  # force_ascii=False 可以保留非 ASCII 字符\n",
    "\n",
    "# 將 JSON 保存到文件\n",
    "with open('ptt-stock.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
